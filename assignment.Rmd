---
title: "MachineLearningAssignment"
author: "CH"
date: "16 MÃ¤rz 2017"
output: html_document
---

# Load data

The datasets are downloaded if they do not already exist in the current directory. We consider "#DIV/0!" as NA.

```{r load data}
library(caret)
library(dplyr)
library(ggplot2)
library(tidyr)

if (!file.exists("pml-training.csv"))
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
                destfile = "pml-training.csv")
if (!file.exists("pml-testing.csv"))
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
                destfile = "pml-testing.csv")

training <- read.csv("pml-training.csv",
                     na.strings = c("NA", "#DIV/0!"))
testing <- read.csv("pml-testing.csv",
                     na.strings = c("NA", "#DIV/0!"))
```

# Preprocessing

The original dataset seems to contain time series data as well as summary data of that describe the data during a certain time window. These summary variables have values only in the rows that contain the new_window value "yes", and therefore, these variables contain mostly NAs and are excluded from the model.

```{r selecting variables}

training <-
  training %>%
  select(-(1:7)) %>%
  select(-starts_with("var"), 
         -starts_with("avg"), 
         -starts_with("min"), 
         -starts_with("max"), 
         -starts_with("skewness"), 
         -starts_with("kurtosis"),
         -starts_with("amplitude"),
         -starts_with("stddev"))


trainingClasse <- training$classe

training <- training %>% select(-matches("classe"))

testing <- 
  testing %>%
  select(-(1:7)) %>%
    select(-starts_with("var"), 
         -starts_with("avg"), 
         -starts_with("min"), 
         -starts_with("max"), 
         -starts_with("skewness"), 
         -starts_with("kurtosis"),
         -starts_with("amplitude"),
         -starts_with("stddev"))

testingID <- testing$problem_id

testing <- testing %>% select(-matches("problem_id"))

print(dim(training))

print(dim(testing))

```


Because some variables seem quite skewed, let's center and scale the variables, and do a BoxCox transformation. A density plot allows screening for the result of the preprocessing procedure.

```{r preprocessing}

ggplot(training %>% gather(variable, value),
       aes(group = variable, x = value)) + geom_density() +
  scale_y_continuous(limits = c(0, 1))

preProp <- preProcess(training, method = c("center", "scale", "BoxCox"))

trainingPreProp <- predict(preProp, training)

testingPreProp <- predict(preProp, testing)

ggplot(trainingPreProp %>% gather(variable, value),
       aes(group = variable, x = value)) + geom_density() +
    scale_y_continuous(limits = c(0, 1))

```

# Model selection using k-fold crossvalidation to estimate out-of-sample error.

I have started using 5-fold crossvalidation for the whole dataset. However, this takes a really long time. Therefore, I have decided to use subsets of the whole dataset to select a model and then use the whole dataset only for the final model.

```{r subsetting for model selection}

trainingFinal <- data.frame(classe = trainingClasse, trainingPreProp)

sset <- createFolds(trainingFinal$classe, 10, list = F)
trainingNew <- trainingFinal[sset == 1,]

```


## Recursive Partitioning

```{r rpart}

folds <- createFolds(trainingNew$classe, 5, list = F)

acc <- c()
for (i in 1:max(folds)) {
  i <- 1
  model <-  train(classe ~ ., method = "rpart",
                  data = trainingNew[folds != i, ])
  acc <- c(acc,
           confusionMatrix(predict(model, trainingNew[folds == i, -1]),
                           trainingNew[folds == i, 1])$overall[1]
  )

}

print(acc)

```

The estimated out-of-sample accuracy for the first model is `r mean(acc)`.

## Random Forest

To speed up model selection, I have decided to reduce k to 3 for random forest and treebag.

```{r rf}

folds <- createFolds(trainingNew$classe, 3, list = F)

acc <- c()
for (i in 1:max(folds)) {
  i <- 1
  model <-  train(classe ~ ., method = "rf",
                  data = trainingNew[folds != i, ])
  acc <- c(acc,
           confusionMatrix(predict(model, trainingNew[folds == i, -1]),
                           trainingNew[folds == i, 1])$overall[1]
  )
  
}

print(acc)

```

The estimated out-of-sample accuracy for the first model is `r mean(acc)`.

## Treebag

```{r treebag}

folds <- createFolds(trainingNew$classe, 3, list = F)

acc <- c()
for (i in 1:max(folds)) {
  i <- 1
  model <-  train(classe ~ ., method = "treebag",
                  data = trainingNew[folds != i, ])
  acc <- c(acc,
           confusionMatrix(predict(model, trainingNew[folds == i, -1]),
                           trainingNew[folds == i, 1])$overall[1]
  )
  
}

print(acc)

```

The estimated out-of-sample accuracy for the first model is `r mean(acc)`.

# Prediction of the test cases

The random forest was the most accurate model, so we are going to use it to predict the test cases.

```{r final model}

finModel <-  train(classe ~ ., method = "rf",
                   data = trainingFinal)

print(data.frame(problem_id = testingID, predict(model, testingPreProp)))

```

